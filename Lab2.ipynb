{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mominali12/ship_edge_test/blob/main/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHYKcWEHTGu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ds-kiel/TinyML-Labs/blob/WS24-25/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ds-kiel/TinyML-Labs/blob/WS24-25/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://raw.githubusercontent.com/ds-kiel/TinyML-Labs/WS24-25/Lab2.ipynb\" download><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdQ1KVS0HZXS"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. Name it *'Group\\<Your group number\\>_Lab2.ipynb'*. <ins>This is the master notebook so you will not be able to save your changes without copying it !</ins> Once you click on that, make sure you are working on that version of the notebook so that your work is saved.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvrMU-DIHePo"
      },
      "source": [
        "# Lab 2: Quantization and On-Device Execution\n",
        "\n",
        "In the first lab you looked at the first part of the pipeline from data to executing models on low-power devices. You explored how to preprocess data and train neural networks with Edge Impulse. In this lab we continue the pipeline and you will explore how to [convert](https://ai.google.dev/edge/litert/models/convert_tf) a model to a [LiteRT](https://ai.google.dev/edge/litert) model, how to [quantize](https://ai.google.dev/edge/litert/models/post_training_integer_quant) [a model](https://www.tensorflow.org/model_optimization/guide/quantization/post_training), how to use [quantization-aware training](https://www.tensorflow.org/model_optimization/guide/quantization/training) and finally how to deploy the model and use the model with a microcontroller.\n",
        "\n",
        "You will explore the full pipeline from data to device using Tensorflow. You will train a model and convert, deploy, and execute it on a microcontroller, specifically the [Arduino Nano 33 BLE Sense](https://store.arduino.cc/products/arduino-tiny-machine-learning-kit).\n",
        "\n",
        "## Environment\n",
        "\n",
        "The instructions for this lab come as a [Jupyter Notebook](https://jupyter.org/). You can run it locally in your own Python environment, but we recommend you to use [Google Colab](https://colab.research.google.com) to save your computer hardware, have an instantly working python environment, and allow for easy collaboration. If your decide to use your local computer, take a look at Python virtual environments to avoid messing with your usual Python environment.\n",
        "\n",
        "Moreover, you need to obtain an API key from an Edge Impulse project. Register at [edgeimpulse.com](https://edgeimpulse.com/), log in and create a new project. Open the project, navigate to **Dashboard** and click on the **Keys** tab to view your API keys. Double-click on the API key to highlight it, right-click, and select **Copy**. Paste the key below in the cell starting with `ei.API_KEY`.\n",
        "\n",
        "![Copy API key from Edge Impulse project](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/python-sdk-copy-ei-api-key.png)\n",
        "\n",
        "For this lab you will not use the project in the Edge Impulse Studio. We just need the API Key.\n",
        "\n",
        "## What do you need to hand in?\n",
        "\n",
        "This Jupyter Notebook is intended as a document that you use both for working on the lab as well as for answering the questions. For handing in your lab, please **upload this Jupyter notebook**. Make sure that all images you include and outputs you generate are visible in the version you hand in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2d8yFY1GUX1"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fOJvKcsUGWH1",
        "outputId": "fb64c624-dda2-47c2-f4bb-bbfda3e78b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting edgeimpulse\n",
            "  Downloading edgeimpulse-1.0.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting cbor2\n",
            "  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting edgeimpulse-api<2.0.0,>=1.61.23 (from edgeimpulse)\n",
            "  Downloading edgeimpulse_api-1.66.29-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting python-socketio<6.0.0,>=5.8.0 (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading python_socketio-5.12.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Collecting aenum<4.0.0,>=3.1.11 (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pydantic<2.0.0,>=1.10.2 (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse)\n",
            "  Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.25.3 (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Collecting bidict>=0.21.0 (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading python_engineio-4.11.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (0.14.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edgeimpulse-1.0.18-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edgeimpulse_api-1.66.29-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_socketio-5.12.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_engineio-4.11.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aenum, wsproto, urllib3, tensorflow-model-optimization, pydantic, cbor2, bidict, simple-websocket, edgeimpulse-api, python-engineio, python-socketio, edgeimpulse\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.32 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain 0.3.16 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "wandb 0.19.5 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aenum-3.1.15 bidict-0.23.1 cbor2-5.6.5 edgeimpulse-1.0.18 edgeimpulse-api-1.66.29 pydantic-1.10.21 python-engineio-4.11.2 python-socketio-5.12.1 simple-websocket-1.1.0 tensorflow-model-optimization-0.8.0 urllib3-1.26.20 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# If you have not done so already, install the following dependencies\n",
        "!python -m pip install tensorflow tensorflow-model-optimization scikit-learn edgeimpulse numpy matplotlib seaborn cbor2 pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTICd15rGZGx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y7yRUuJUGaq-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import cbor2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# from tensorflow.lite import TFLiteConverter\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import edgeimpulse as ei\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhIKkymAGfqu"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WRxTHnJcGk0a"
      },
      "outputs": [],
      "source": [
        "# plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle(f'Model {model_name}')\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "    ax1.plot(range(1, len(history.history['accuracy'])+1), history.history['accuracy'])\n",
        "    ax1.plot(range(1, len(history.history['val_accuracy'])+1), history.history['val_accuracy'])\n",
        "    ax1.set_title('Model accuracy')\n",
        "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "    ax1.legend(['training', 'validation'], loc='best')\n",
        "\n",
        "    ax2.plot(range(1, len(history.history['loss'])+1), history.history['loss'])\n",
        "    ax2.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'])\n",
        "    ax2.set_title('Model loss')\n",
        "    ax2.set(xlabel='epoch', ylabel='loss')\n",
        "    ax2.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62RGknKGGopG"
      },
      "source": [
        "### Edge Impulse API Key\n",
        "\n",
        "Insert your Edge Impulse API Key as in Lab 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ERLWd1g2GzXd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "ei.API_KEY = 'ei_b81013a567f75902030a05e760e094565751cd746cae48eaa40baea5c0262397' #userdata.get('edge_impulse') # Change this to your Edge Impulse API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9j7urCG-6E"
      },
      "source": [
        "## Edge Impulse Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZUVTQ2TIA10"
      },
      "source": [
        "### Prepare the data\n",
        "\n",
        "---\n",
        "**Task 1:** Navigate to the *Data acquisition* page in your Edge Impulse project of lab 1 and export the data.\n",
        "\n",
        "**Task 2:** Import the data with the code below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jim_ewe0gonE"
      },
      "outputs": [],
      "source": [
        "# labels = list(range(0,224)) # Change this to your labels\n",
        "# num_classes = len(labels)\n",
        "\n",
        "# data_path = '...' # Change this to the path of your downloaded folder\n",
        "\n",
        "# # Select the window size and stride you used in Edge Impulse\n",
        "# window_size_ms = 2000\n",
        "# window_stride_ms = 100\n",
        "\n",
        "\n",
        "# # Function to create windows from the data\n",
        "# def create_windows(df, window_size_ms, window_stride_ms, label):\n",
        "#     window_size = int(window_size_ms / 10)\n",
        "#     window_stride = int(window_stride_ms / 10)\n",
        "#     windows = []\n",
        "#     windows_labels = []\n",
        "#     for i in range(0, len(df) - window_size, window_stride):\n",
        "#         windows.append(df.iloc[i:i+window_size].values)\n",
        "#         windows_labels.append(label)\n",
        "#     return np.array(windows),windows_labels\n",
        "\n",
        "# # Load the data from the files\n",
        "# def load_data(data_path, folder):\n",
        "#     data = np.zeros((1, int(window_size_ms / 10), 3))\n",
        "#     data_labels = []\n",
        "#     for file in os.listdir(data_path+folder):\n",
        "#         if file.endswith('.cbor'):\n",
        "#             label = file.split('.')[0].strip()\n",
        "#             with open(data_path+folder+'/'+file, 'rb') as f_obj:\n",
        "#                 data_file = cbor2.load(f_obj)\n",
        "#                 df = pd.DataFrame(data_file['payload']['values'], columns=[item['name'] for item in data_file['payload']['sensors']])\n",
        "#                 df = df.drop(columns=['gyrX', 'gyrY', 'gyrZ', 'magX', 'magY', 'magZ'])\n",
        "\n",
        "#                 window_data, window_labels = create_windows(df, window_size_ms, window_stride_ms, labels.index(label))\n",
        "#                 data = np.concatenate((data, window_data), axis=0)\n",
        "#                 data_labels += window_labels\n",
        "\n",
        "#     data = np.delete(data, 0, axis=0)\n",
        "#     return data, data_labels\n",
        "\n",
        "\n",
        "# x_train, y_train = load_data(data_path, 'training')\n",
        "# x_test, y_test = load_data(data_path, 'testing')\n",
        "\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_DpceIAgonE"
      },
      "source": [
        "---\n",
        "**Task 3 (optional):** Perform scaling on your data if you like to. *Please note: You have to do the same scaling later in your Arduino program.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYxsoS-GgonE"
      },
      "outputs": [],
      "source": [
        "# perform your scaling here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt8W5N0UIHtY"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "---\n",
        "**Task 4:** Add your best model from lab 1, that uses a raw data preprocessing block.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWq43Tx6HxN1"
      },
      "outputs": [],
      "source": [
        "# # Build model\n",
        "# def build_model(summary=True):\n",
        "#     model = Sequential()\n",
        "\n",
        "#     # ADD YOUR LAYERS HERE\n",
        "\n",
        "#     model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#     # Compile model_mnist\n",
        "#     model.compile(\n",
        "#         optimizer='adam',\n",
        "#         loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "#     if summary:\n",
        "#         model.summary()\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sSs127krIdEc"
      },
      "outputs": [],
      "source": [
        "# model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1n_O2a6I0ee"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "So far, you manually explored how many epochs are necessary to successfully train the model. However, Tensorflow gives you an option to automate this called [early stopping](https://keras.io/api/callbacks/early_stopping/). See also [here](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) and [here](https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd).\n",
        "\n",
        "---\n",
        "**Task 7:** Use an early stopping callback in your fitting function to find the optimal number of epochs. Use reasonable configurations. How many epochs does it train for?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aCrSiGBcI2ot"
      },
      "outputs": [],
      "source": [
        "# early_stopping_cb = EarlyStopping(\n",
        "#     monitor=...,\n",
        "#     patience=...,\n",
        "#     min_delta=...,\n",
        "#     mode=...\n",
        "# )\n",
        "\n",
        "# num_epochs = 200\n",
        "# history = model.fit(x_train, y_train, batch_size=128, epochs=num_epochs, validation_split=0.1, callbacks=[early_stopping_cb])\n",
        "# plot_training_history(history, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFR6XlSJgonF"
      },
      "source": [
        "### Evaluate the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6lvkkAE8gonF"
      },
      "outputs": [],
      "source": [
        "# score_model = model.evaluate(x_test, y_test) #, verbose=0)\n",
        "# print(\"Test loss:\", score_model[0])\n",
        "# print(\"Test accuracy:\", score_model[1])\n",
        "\n",
        "# cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(model.predict(x_test),axis=1))\n",
        "# # print(cm)\n",
        "\n",
        "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# cm = pd.DataFrame(cm, index = labels,\n",
        "#                   columns = labels)\n",
        "\n",
        "# plt.figure(figsize = (4,4))\n",
        "# ax = sns.heatmap(cm*100,\n",
        "#            annot=True,\n",
        "#            fmt='.1f',\n",
        "#            cmap=\"Blues\",\n",
        "#            cbar=False,\n",
        "#               )\n",
        "# ax.set_ylabel(\"True Class\", fontdict= {'fontweight':'bold'})\n",
        "# ax.set_xlabel(\"Predicted Class\", fontdict= {'fontweight':'bold'})\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSKUhvQgonF"
      },
      "source": [
        "---\n",
        "**Task 8:** How does the accuracy of your model compare to the accuracy you achieved with Edge Impulse?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58FOt106gonF"
      },
      "source": [
        "### On-device resource consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab8wuW0UgonF"
      },
      "source": [
        "After training your model, we want to know whether we can run it on a microcontroller or whether it is too large. We will use the [Edge Impulse Python SDK](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk) for profiling, so if you didn't add your API key on top, now is the time.\n",
        "\n",
        "To start, we need to find the right target device for profiling. You are looking for the *Arduino Nano 33 BLE*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eocc_g7lgonF"
      },
      "outputs": [],
      "source": [
        "# List the available profile target devices\n",
        "# ei.model.list_profile_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST8vgqZ1gonF"
      },
      "source": [
        "Next you can estimate the memory usage and inference time for each of your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ju-pxDE5gonF"
      },
      "outputs": [],
      "source": [
        "# # Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "\n",
        "# your_model = ...\n",
        "# your_device = ...\n",
        "\n",
        "# try:\n",
        "#     profile = ei.model.profile(model=your_model,\n",
        "#                                device=your_device)\n",
        "#     print(profile.summary())\n",
        "# except Exception as e:\n",
        "#     print(f\"Could not profile: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znyz7E-DgonG"
      },
      "source": [
        "---\n",
        "**Task 9:** Estimate the memory usage and inference time for your modes. **Compare your model's performance to your Edge Impulse models regarding ROM and RAM usage and their inference time**. Please do **<ins>not</ins>** use a table for this, but plot it, for example with [Matplotlib](https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_colors.html) or [Seaborn](https://seaborn.pydata.org/examples/grouped_barplot.html). Bar plots should be a good option for it. On the x-axis you can list the model and on the y-axis, you can show the respective memory usage for ROM and RAM.\n",
        "\n",
        "**Task 10:** Briefly explain your plot(s) of task 9.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lnvqismgonG"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "To come back to a model to continue working on it, it might be useful to save it. We can use the `model.save()` [Function](https://www.tensorflow.org/guide/keras/serialization_and_saving) that exports a TensorFlow model object to SavedModel format.\n",
        "\n",
        "If you use Google Colab, you can find the saved model as a `.keras`-file on the left under `Files/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OUOynGrDgonG"
      },
      "outputs": [],
      "source": [
        "# export_path = 'saved_model.keras'\n",
        "# model.save(export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYguQ6iAgonG"
      },
      "source": [
        "### Model Quantization\n",
        "\n",
        "Your microcontroller cannot use the Tensoflow model directly. Instead there is [LiteRT](https://ai.google.dev/edge/litert) for deploying models on mobile and edge devices.\n",
        "\n",
        "---\n",
        "**Task 11:** Load your model and convert it with LiteRT and save the model to a `.tflite`-file. (HINT: Check out [this](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/hello_world) *Hello World* example and [these instructions](https://ai.google.dev/edge/litert/models/convert_tf).)\n",
        "\n",
        "**Task 12:** Create a second LiteRT conversion that uses [optimizations](https://ai.google.dev/edge/api/tflite/python/tf/lite/Optimize) and enforce integer-only weights.\n",
        "(Maybe a helpful [resource](https://ai.google.dev/edge/litert/models/post_training_quantization).)\n",
        "\n",
        "**Task 13:** Create a third Tensorflow Lite conversion that in addition to the conversion in *Task 12* enforces integer-only quantization. (*Hint: Use a [representative dataset](https://ai.google.dev/edge/api/tflite/python/tf/lite/RepresentativeDataset).*)\n",
        "\n",
        "**Task 14:** Evaluate all three converted models and compare them to the Tensorflow model they are based on regarding profiled memory usage and accuracy. Use plots.\n",
        "\n",
        "**Task 15:** Explain your findings from Task 14. Why is there such a difference in performance and in memory usage?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN5hL20ngonG"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR MODEL CONVERSIONS HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an2BsNOcgonG"
      },
      "outputs": [],
      "source": [
        "# # Save the converted model\n",
        "\n",
        "# with open('model.tflite', 'wb') as f:\n",
        "#     f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBc7JSugonG"
      },
      "source": [
        "### Quantization Aware Training\n",
        "\n",
        "To improve on the performance of your converted models, you can use Quantization Aware Training before converting the model.\n",
        "\n",
        "---\n",
        "**Task 16:** Run the code below and explain the resulting model.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FghknkjogonG"
      },
      "outputs": [],
      "source": [
        "# model = keras.models.load_model('saved_model.keras')\n",
        "# quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# # q_aware stands for for quantization aware.\n",
        "# q_aware_model = quantize_model(model)\n",
        "\n",
        "# # `quantize_model` requires a recompile.\n",
        "# q_aware_model.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6FoSj1dgonG"
      },
      "source": [
        "---\n",
        "**Task 17:** Train (fit) the model and save it for future use. Make sensible choices for the number of epochs. Show the training performance.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lt6haUTgonG"
      },
      "outputs": [],
      "source": [
        "# TRAIN THE MODEL HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYM8-6bTgonN"
      },
      "source": [
        "---\n",
        "**Task 18:** Quantize this model. And save it.\n",
        "\n",
        "**Task 19:** Evaluate the performance of the model after quantization-aware training and after additional quantization. Set it into perspective to the original model and the best quantized version of the original model. Compare memory usage and accuracy. Use plots. (You should compare 4 models here.)\n",
        "\n",
        "**Task 20:** Explain your findings from *Task 19*.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhwCpME5gonN"
      },
      "source": [
        "### Model Export - Library Creation\n",
        "\n",
        "Up until now we created different models that we can test and evaluate using Python. However, most microcontrollers don't speak Python. Instead they work with C/C++ and thus we need a C(++) library of the models to execute it. Here you explore different ways to export your models to a C(++) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K94RDUPNgonN"
      },
      "source": [
        "#### Manual conversion of the model\n",
        "\n",
        "---\n",
        "**Task 21:** Convert your best performing quantized model to a C++ library with the code below and explain the content of the two resulting files.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qYVVh08NgonN",
        "outputId": "59d12bb4-899f-44fe-9eb4-c8454b5c9f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [1 InRelease 22.9 kB/129 kB 18%] [Connected to \r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connected to cloud.r-project.org (65.9.86.109)\r                                                                                                    \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [2 InRelease 3,626 B/3,626 B 100%] [Connecting to r2u.stat.illinois.edu (19\r0% [Waiting for headers] [Connecting to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers\r                                                                                                    \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,904 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,640 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,521 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,647 kB]\n",
            "Fetched 21.2 MB in 3s (7,176 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get -qq install xxd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZYIAs7SIgonN"
      },
      "outputs": [],
      "source": [
        "MODEL_TFLITE = '/content/ship_models/lstm_spectrogram.tflite' #enter the name of your TFlite file uploaded to the folders section\n",
        "MODEL_TFLITE_MICRO = '/content/ship_models/lstm_spectrogram.cc' #update the name of your .cc file (This can be anything)\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TFLITE = '/content/ship_models/mobilenet_spectrogram.tflite' #enter the name of your TFlite file uploaded to the folders section\n",
        "MODEL_TFLITE_MICRO = '/content/ship_models/mobilenet_spectrogram.cc' #update the name of your .cc file (This can be anything)\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ],
      "metadata": {
        "id": "dorFv3Xp_OQn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(range(0,181))\n",
        "for i,v in enumerate(labels):\n",
        "  labels[i] = str(v)"
      ],
      "metadata": {
        "id": "J2cjiYnqwP-6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B3SP-ga_gonN"
      },
      "outputs": [],
      "source": [
        "LIBRARY_NAME = 'lstm_spectrogram_lib' #update here\n",
        "# max_label_str_length = max([len(lbl) for lbl in labels]) + 1\n",
        "max_label_str_length = max([len(lbl) for lbl in labels]) + 1\n",
        "\n",
        "model_str = f\"alignas(16) const unsigned char {LIBRARY_NAME}[] = \"\n",
        "with open(MODEL_TFLITE_MICRO, 'r') as file:\n",
        "    data = file.read();\n",
        "    model_str += data[data.index(\"{\"): len(data)].replace(\"unsigned\", \"const\")\n",
        "\n",
        "labels_str = f\"const char available_classes[][{max_label_str_length}] = {{\"\n",
        "for i in range(0, len(labels)):\n",
        "    if i != 0:\n",
        "        labels_str += \", \"\n",
        "    labels_str += \"\\\"\"+labels[i]+\"\\\"\"\n",
        "labels_str += \"};\"\n",
        "\n",
        "output_str = f\"#include \\\"{LIBRARY_NAME}.h\\\"\\n\"\n",
        "output_str += labels_str + \"\\n\"\n",
        "output_str += \"const int available_classes_num = \"+str(len(labels)) +\";\\n\"\n",
        "output_str += model_str\n",
        "\n",
        "with open(f\"{LIBRARY_NAME}.cpp\", \"w\") as file:\n",
        "    file.write(output_str)\n",
        "\n",
        "header_str = \"#ifndef TENSORFLOW_LITE_MODEL_H_\\n#define TENSORFLOW_LITE_MODEL_H_\\n\\n\"\n",
        "header_str += \"// Classes that can be detected by the neural network\\n\"\n",
        "header_str += f\"extern const char available_classes[][{max_label_str_length}];\\n\"\n",
        "header_str += \"extern const int available_classes_num;\\n\\n\"\n",
        "header_str += \"// Pre-trained netural network\\n\"\n",
        "header_str += f\"extern const unsigned char {LIBRARY_NAME}[];\\n\"\n",
        "header_str += f\"extern const int {LIBRARY_NAME}_len;\\n\\n\"\n",
        "header_str += \"#endif /* TENSORFLOW_LITE_MODEL_H_ */\"\n",
        "\n",
        "with open(f\"{LIBRARY_NAME}.h\", \"w\") as file:\n",
        "    file.write(header_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5U_4trRgonN"
      },
      "source": [
        "Next you will use your library in an Arduino program to (or if you prefer, in a Zephyr program) and execute the [inference on a microcontroller](https://ai.google.dev/edge/litert/microcontrollers/get_started). I strongly recommend you to use [this](https://docs.arduino.cc/tutorials/nano-33-ble-sense/get-started-with-machine-learning) Arduino example as a starting point to write the code. (If you prefer to use Zephyr, have a look at [this](https://github.com/ds-kiel/blueseer/) repository.)\n",
        "\n",
        "---\n",
        "**Task 22:** Write an Arduino (or Zephyr) program that records and uses a movement as input, classifies the gesture and reports the result back to you through the serial interface.\n",
        "\n",
        "**Task 23:** Upload the program to the Arduino and compare the real memory usage with the Edge Impulse estimate. Was the estimate correct? How much does it differ?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 24:** Extend your Arduino program and measure the inference time on the Arduino. Was the estimate correct?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 25:** Perform inference for at least 20 gestures and plot statistics (e.g., bar plot (mean) with error bar (standard deviation)) for the inference time. Does it vary? Why or why not?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZiHYx68gonN"
      },
      "source": [
        "### Model conversion and library creation with Edge Impulse\n",
        "\n",
        "In the last lab, you trained a model with Edge Impulse. Now we want to continue with that model and compare its on-device performance with your locally trained model.\n",
        "\n",
        "---\n",
        "**Task 26:** Head to your dashboard of the project of lab 1 and download the quantized models of your classifiers. Head to [https://netron.app/](https://netron.app/) and open your models with it. Click on the input or output layer and take a look at the quantization equations. Are the quantization equations the same for each of your classifiers? Why (not)?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 27:** Build two Arduino Libraries for your best performing model – one with enabling the EON Compiler and one without. (You might have to create an impulse containing only a single model.) For both libraries, use the quantized version. What is the EON Compiler, and why is the memory usage so different between the two libraries? Compare the models included in the two libraries (in `src > tflite-model`). How do they differ? What makes one of them smaller?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 28:** Include the libraries into your Arduino IDE (`Add .ZIP Library...`). Open the accelerometer example that comes with your library and flash it to your board. Open a serial monitor. Explain the Arduino program and the output of the serial monitor. Also, why is there a reference to numpy in the Arduino program? How is that possible in C++? Evaluate how well and how fast the classification works for each of your motions. Is there a difference in performance between the two Arduino libraries?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 29:** Compare the memory usage and performance of the two Edge Impulse models with your locally trained model. How do they compare? Please create plots.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "**Task 30 (optional):** You can also create an Arduino library with your locally trained model. Explore how to use Edge Impulse to [create a library](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk) to deploy your local model. First, check the available target devices for deployment (`ei.model.list_deployment_targets()`) and find the correct Arduino corresponding to your hardware. Create an Arduino Library with Edge Impulse and compare its performance with the libraries above.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}